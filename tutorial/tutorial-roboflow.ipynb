{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116bf675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pyyaml roboflow ultralytics --quiet\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "#get custom functions to use\n",
    "sys.path.append('../')\n",
    "from myutils import track_droplet\n",
    "from plot_utils import add_speed, plot_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c56040",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Particle Detection Dataset with Roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16465f5",
   "metadata": {},
   "source": [
    "1. One convenient way of creating an object detection dataset is [Roboflow](https://roboflow.com/). Here is a short [tutorial](https://youtu.be/a3SBRtILjPI). If this is your first time doing this, please do not proceed without watching the tutorials.\n",
    "\n",
    "2. Drag and drop your experiment video into Roboflow and start annotating. Generally speaking, 80-100 frames should be enough based on your experience.\n",
    "\n",
    "3. We only have one object class 'droplet'. So create bounding boxes around the particle of interests. *Note that our model works only with a single particle entity.* In this case, walking droplets or granular intruders.\n",
    "\n",
    "4. We already created a public dataset for a walking droplet experiment having 3 walkers in it. You can export it from Roboflow and introduce to your worksapce as follows. The procedure will be exactly the same if you use your own data with different API keys and project name etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b97372-1ee8-42b9-b7ad-9c5fde18d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Roboflow(api_key=\"WW6dCyTFMI8b51n0TdS7\")\n",
    "project = rf.workspace(\"droplets-hx0xu\").project(\"walkers-eyx4s\")\n",
    "dataset = project.version(1).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ddaae1-b290-4af5-ac74-f26a136c91f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "**READ CAREFULLY**: \n",
    "- The code snippet above will download a folder named \"walkers-1\" in which we have annotated images as well as a \"data.yaml\" file pointing to necessary folders. \n",
    "- However, there is a small bug in YOLOv8 such that annotations must be in the folder named *\"datasets\"* and thus the path to \"data.yaml\" must be modified. - - \n",
    "\n",
    "- Please run the following function by providing the original folder name. This will modify your folder accordingly. Run this function only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4fb9f3-f904-4515-bc09-32c1fc8d938d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def modify_yaml(project_name):\n",
    "    #pip install pyyaml\n",
    "    import yaml\n",
    "    import os\n",
    "\n",
    "\n",
    "    # Step 1: Rename the folder\n",
    "    new_folder_name = \"datasets\"\n",
    "    \n",
    "    # Check if the 'walkers' folder exists. If not, exit.\n",
    "    if not os.path.exists(project_name):\n",
    "        print(f\"no folder named '{project_name}', please check the folder name downloaded from Roboflow \")\n",
    "        exit()\n",
    "    \n",
    "    \n",
    "    #Remove the 'datasets' folder if it exists\n",
    "    if os.path.exists(new_folder_name):\n",
    "        shutil.rmtree(new_folder_name)\n",
    "\n",
    "    if os.path.exists(project_name):\n",
    "        os.rename(project_name, new_folder_name)\n",
    "\n",
    "    # Step 2: Modify the data.yaml file\n",
    "    yaml_file_path = os.path.join(new_folder_name, \"data.yaml\")\n",
    "\n",
    "    # Read the YAML data\n",
    "    with open(yaml_file_path, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "\n",
    "    # Modify the YAML data\n",
    "    data[\"path\"] = os.path.abspath(new_folder_name)  # add full path\n",
    "    data[\"test\"] = \"test/images\"\n",
    "    data[\"train\"] = \"train/images\"\n",
    "    data[\"val\"] = \"valid/images\"\n",
    "\n",
    "    # Write the modified data back to the YAML file\n",
    "    with open(yaml_file_path, 'w') as file:\n",
    "        yaml.dump(data, file)\n",
    "    \n",
    "#change the project name(folder name) accordingly. this is the original folder dowloaded by the code snippet above.    \n",
    "modify_yaml(\"walkers-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397fb7c-a789-4f56-b4b6-eae4a38b10f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29d3b78d",
   "metadata": {},
   "source": [
    "# Traning YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef2e37-300e-4c4c-98e9-2d0cc96edd16",
   "metadata": {},
   "source": [
    "## I **dont** have a local GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95efa8e-57a2-49d4-b31e-5f7440f6a5e2",
   "metadata": {},
   "source": [
    "- If you dont have a local GPU, the training procedure takes too long. In this case, we will train the model on Google Colab. And download the best model into \"tutorial\" folder we are working in.\n",
    "\n",
    "- We createad a notebook on Colab, please **[click here](https://drive.google.com/file/d/1C1Oso_4lpQYy9qzhgaJHyEm_xe9nck40/view?usp=sharing)** to access. It will walk through the process, it is very simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f5a4f-e84e-4538-8122-e458229dc103",
   "metadata": {},
   "source": [
    "## I **do** have a local GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b178970b-7873-4119-af3e-dcf975974aa5",
   "metadata": {},
   "source": [
    "- The following option for model training is self-explanatory. We will save all the YOLO tranining results into *\"project/name\"* folder. In the same folder, you will find tons of useful information. The ones we will definetely use is /weights/best.pt' which is the best model of our tranining. We will load and use the best model in the rest of the notebook. \n",
    "\n",
    "\n",
    "- You can experiment with different pretrained models; yolov8n, yolov8s, yolov8m, yolov8l, yolov8x(increasing in size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482551e5-8a1f-4487-9044-4bccfeb489ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main yaml directory\n",
    "data = 'datasets/data.yaml'\n",
    "\n",
    "#save all yolo results here\n",
    "yolo_results = 'yolo_results'\n",
    "\n",
    "#save tranining results to yolo_results/experiment_name\n",
    "experiment_name = \"sample_project\"\n",
    "\n",
    "#overwrite the traning results for different trials\n",
    "exist_ok = True\n",
    "\n",
    "#number of epochs\n",
    "epochs = 200\n",
    "\n",
    "#reproducibility\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b8d79-8938-447f-98b8-fcef2da49a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and train the model\n",
    "model = YOLO('yolov8n.yaml')\n",
    "model = YOLO('yolov8n.pt') \n",
    "\n",
    "model.train(data=data, epochs=epochs,project=yolo_results,name=experiment_name,exist_ok=exist_ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deb4c48",
   "metadata": {},
   "source": [
    "- **If *mAP50* value on testing data is way below 0.90, that means the model did not learn enough thus will likely to fail in real-time tracker. Based on our experience, first start by increasing the the number of epochs to a high number say 400. If the behaviour is the same, increasing the number of training images may help. Add 20-30 images/labels to the training data. You can also increase the batch_size**. \n",
    "\n",
    "- Make sure to inspect the results in \"\"project/name\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd88247-6f13-462f-aba2-27e03abffad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fb2b7fe",
   "metadata": {},
   "source": [
    "# Droplet/Intruder Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88927283",
   "metadata": {},
   "source": [
    "- Once the model is trained, you will find the best model at  f\"{project}/{name}/weights/best.pt\" as noted above. **If you trained your model and download it from there, please change model_path accordingly**. \n",
    "\n",
    "\n",
    "To visualize and save the tracking results, simply modify the following cell. **track_droplet** displays the tracking in real-time and saves the trajectories to *save_dir/save_name.csv* which we will discuss in a bit. Ignore if you get \"QObject::moveToThread\" error. The same function also saves the tracking video in the same directory.\n",
    "\n",
    "\n",
    "- Make sure to properly enter all the arguments. If you spot any false positives, try increasing the threshold slightly. You can always interrupt the simulation by pressing \"q\" on your keyboard. All information is saved in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0743bb-29b5-4c95-af82-7ac09ed88646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = f\"{yolo_results}/{experiment_name}/weights/best.pt\"\n",
    "model = YOLO(model_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d8e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of particles in the experiment\n",
    "num_particle = 3\n",
    "\n",
    "#experiment video to be tracked, defined at the top\n",
    "video_path = \"../../TrackingDroplets-YOLOv8/dataset/videos/three_droplet.mp4\"\n",
    "\n",
    "#accept detections only above this confidance\n",
    "conf_thresold = 0.45\n",
    "\n",
    "#save tracks and tracking video here\n",
    "save_dir = 'tracking_results'\n",
    "\n",
    "#name your experiment\n",
    "save_name = experiment_name\n",
    "\n",
    "#show trajectory or just bounding box with IDs\n",
    "show_trace = True\n",
    "\n",
    "# #run the tracker\n",
    "track_droplet(model=model, num_particle=num_particle, video_path=video_path, conf_thresold=conf_thresold,\n",
    "                                        save_dir=save_dir, save_name=save_name, show_trace=show_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43cbb37-4b93-4ca9-a553-ea9e070eebdd",
   "metadata": {},
   "source": [
    "                    experiment: sample_project detection_rate: 8909/9033 = 98.627%\n",
    "                    trajectories saved to tracking_results/sample_project.csv\n",
    "\n",
    "                    (8909, 9033, 185.93071365356445)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942b7d7-4eb6-4ebf-8ff5-3d79b2af5894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b43368c4",
   "metadata": {},
   "source": [
    "# Inspecting Results and Some Post-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ef590",
   "metadata": {},
   "source": [
    "- Let's inspect the results regarding our original experiment.We will start by loading the dataframe we saved. You can analyze this data in a way you wish. \n",
    "\n",
    "\n",
    "- **frame_id, time, x, y, c** columns refers to the frame number, time stamp(sec), x-position,y-position of each individual droplet/intruder tracked. detected=1 means we detected precisely 3 particles(which is different in other experiments) in that frame with confidance score 0.45 we set above. This ensures we dont get false positives. detected=0 rows has only frame_id and time properties. It can be useful for diagnosis purposes. \n",
    "\n",
    "\n",
    "- For example, using the plot function below, we can overlay the position and the flow of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2380bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f\"{save_dir}/{save_name}.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a98a39-f7f0-4150-b025-cea84b73fb11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edd017-7658-4219-b70b-cbf20bf5f8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0f0af-f164-4588-ad9b-5e4a0b0c1469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_with_speed = add_speed(data=data,num_particle=3)\n",
    "df_with_speed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a5f62-a0b8-4ead-a912-c53d352d6708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365dc3b-e0a7-49f9-8c90-fc842cb5df3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#square: inital point; circle:terminal point, you can enter num_particle=3 to see all speed maps\n",
    "plot_speed(data=data,num_particle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac21d456-4395-4dc2-8e50-74233a607c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063dccd6-0f76-45fe-ba5b-02b36de5a975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1aee67ff",
   "metadata": {},
   "source": [
    "## Use Different Trackers with YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa04207",
   "metadata": {},
   "source": [
    "- Any tracking-by-detection method can operate on YOLOv8 detection. [yolov8_tracker](https://github.com/mikel-brostrom/yolov8_tracking) by mikel-brostrom is an amazing tool to directly obtain the tracks from SOTA trackers on top of YOLOv8. As fas as I can see, 'strongsort', 'deepocsort', 'ocsort', 'bytetrack' and 'botsort' are supported there. Following is a simple implemantation. You can experiment with different tracker. \n",
    "\n",
    "\n",
    "- As we discussed in our paper, **these models suffer from multiple ID switches in all multiple droplet experiments. Thus, their results cannot be used by any means for multiple walking droplet experiments**. However, they can be useful for single particle tracking or some other experiments. It is not a good practice to run the command line arguments from Jupyter but this is just a demo. \n",
    "\n",
    "- Restart the notebook if you encounter any error in the following cell. This library appears to have some compatibility issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80fef8d-c00c-43b1-8957-32622e574625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of tracking methods ['strongsort', 'deepocsort', 'ocsort', 'bytetrack', 'botsort']\n",
    "tracking_method = 'strongsort'\n",
    "\n",
    "# Root directory for all tutorial data\n",
    "track_dir = 'sota_tracker'\n",
    "\n",
    "# Accept detections above this\n",
    "conf_thresold = 0.45\n",
    "\n",
    "#experiment name\n",
    "exp_name = 'strongsort_track'\n",
    "\n",
    "video_path = video_path\n",
    "\n",
    "os.system(f\"python ../yolov8_tracking/track.py --yolo-weights {model_path} --tracking-method {tracking_method}\\\n",
    "          --source {video_path} --conf-thres {conf_thresold} \\\n",
    "          --project {track_dir} --name {exp_name} \\\n",
    "          --show-vid --save-txt --save-vid \\\n",
    "          \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7c4aa-29a9-480b-ae2e-5b30e19ce40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7877d1f4",
   "metadata": {},
   "source": [
    "                                               THANK YOU FOR CHECKING OUT!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
